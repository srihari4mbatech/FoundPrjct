{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data = pd.read_csv(\"./final_ford_analysis_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stock_data = stock_data[[ 'Date', 'Open', 'High', 'Low', 'Close', 'Volume',\n",
    "       'Dividends', 'Stock Splits', 'POSITIVE', 'NEGATIVE', 'NEUTRAL', 'primary_anger',\n",
    "       'primary_fear', 'primary_joy', 'primary_neutral', 'primary_sadness',\n",
    "       'primary_surprise', 'secondary_anger', 'secondary_fear',\n",
    "       'secondary_joy', 'secondary_neutral', 'secondary_sadness',\n",
    "       'secondary_surprise', 'Target_closing_price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Dividends',\n",
       "       'Stock Splits', 'POSITIVE', 'NEGATIVE', 'NEUTRAL', 'primary_anger',\n",
       "       'primary_fear', 'primary_joy', 'primary_neutral', 'primary_sadness',\n",
       "       'primary_surprise', 'secondary_anger', 'secondary_fear',\n",
       "       'secondary_joy', 'secondary_neutral', 'secondary_sadness',\n",
       "       'secondary_surprise', 'Target_closing_price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52 entries, 0 to 51\n",
      "Data columns (total 24 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Date                  52 non-null     object \n",
      " 1   Open                  52 non-null     float64\n",
      " 2   High                  52 non-null     float64\n",
      " 3   Low                   52 non-null     float64\n",
      " 4   Close                 52 non-null     float64\n",
      " 5   Volume                52 non-null     int64  \n",
      " 6   Dividends             52 non-null     float64\n",
      " 7   Stock Splits          52 non-null     int64  \n",
      " 8   POSITIVE              52 non-null     float64\n",
      " 9   NEGATIVE              52 non-null     float64\n",
      " 10  NEUTRAL               52 non-null     float64\n",
      " 11  primary_anger         52 non-null     float64\n",
      " 12  primary_fear          52 non-null     float64\n",
      " 13  primary_joy           52 non-null     float64\n",
      " 14  primary_neutral       52 non-null     float64\n",
      " 15  primary_sadness       52 non-null     float64\n",
      " 16  primary_surprise      52 non-null     float64\n",
      " 17  secondary_anger       52 non-null     float64\n",
      " 18  secondary_fear        52 non-null     float64\n",
      " 19  secondary_joy         52 non-null     float64\n",
      " 20  secondary_neutral     52 non-null     float64\n",
      " 21  secondary_sadness     52 non-null     float64\n",
      " 22  secondary_surprise    52 non-null     float64\n",
      " 23  Target_closing_price  52 non-null     float64\n",
      "dtypes: float64(21), int64(2), object(1)\n",
      "memory usage: 9.9+ KB\n"
     ]
    }
   ],
   "source": [
    "stock_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target variable (y)\n",
    "X = stock_data[['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends',\n",
    "       'Stock Splits', 'POSITIVE', 'NEGATIVE', 'NEUTRAL', 'primary_anger',\n",
    "       'primary_fear', 'primary_joy', 'primary_neutral', 'primary_sadness',\n",
    "       'primary_surprise', 'secondary_anger', 'secondary_fear',\n",
    "       'secondary_joy', 'secondary_neutral', 'secondary_sadness',\n",
    "       'secondary_surprise']]\n",
    "y = stock_data['Target_closing_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a linear regression model\n",
    "regression_model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "regression_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make predictions on the test set\n",
    "predictions = regression_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (Linear Regression): 1.4267887879612553\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f'Mean Squared Error (Linear Regression): {mse}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(stock_data[[ 'Open', 'High', 'Low', 'Close', 'Volume', 'POSITIVE', 'NEGATIVE', 'NEUTRAL', 'primary_anger',\n",
    "       'primary_fear', 'primary_joy', 'primary_neutral', 'primary_sadness',\n",
    "       'primary_surprise', 'secondary_anger', 'secondary_fear',\n",
    "       'secondary_joy', 'secondary_neutral', 'secondary_sadness',\n",
    "       'secondary_surprise']])\n",
    "normalized_df = pd.DataFrame(normalized_data, columns=['Open', 'High', 'Low', 'Close', 'Volume', 'POSITIVE', 'NEGATIVE', 'NEUTRAL', 'primary_anger',\n",
    "       'primary_fear', 'primary_joy', 'primary_neutral', 'primary_sadness',\n",
    "       'primary_surprise', 'secondary_anger', 'secondary_fear',\n",
    "       'secondary_joy', 'secondary_neutral', 'secondary_sadness',\n",
    "       'secondary_surprise'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.joblib']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(scaler, \"scaler.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52, 20), (52,))"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define features (X) and target variable (y)\n",
    "X = normalized_df[['Open', 'High', 'Low', 'Close', 'Volume', 'POSITIVE', 'NEGATIVE', 'NEUTRAL', 'primary_anger',\n",
    "       'primary_fear', 'primary_joy', 'primary_neutral', 'primary_sadness',\n",
    "       'primary_surprise', 'secondary_anger', 'secondary_fear',\n",
    "       'secondary_joy', 'secondary_neutral', 'secondary_sadness',\n",
    "       'secondary_surprise']]\n",
    "y = stock_data['Target_closing_price']\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "5/5 - 1s - loss: 136.9655 - val_loss: 119.0503 - 1s/epoch - 212ms/step\n",
      "Epoch 2/250\n",
      "5/5 - 0s - loss: 129.5419 - val_loss: 112.6430 - 80ms/epoch - 16ms/step\n",
      "Epoch 3/250\n",
      "5/5 - 0s - loss: 121.7493 - val_loss: 105.4066 - 81ms/epoch - 16ms/step\n",
      "Epoch 4/250\n",
      "5/5 - 0s - loss: 113.0367 - val_loss: 97.1434 - 56ms/epoch - 11ms/step\n",
      "Epoch 5/250\n",
      "5/5 - 0s - loss: 103.2264 - val_loss: 87.9147 - 62ms/epoch - 12ms/step\n",
      "Epoch 6/250\n",
      "5/5 - 0s - loss: 92.3560 - val_loss: 77.8484 - 57ms/epoch - 11ms/step\n",
      "Epoch 7/250\n",
      "5/5 - 0s - loss: 80.2601 - val_loss: 66.7480 - 57ms/epoch - 11ms/step\n",
      "Epoch 8/250\n",
      "5/5 - 0s - loss: 67.2926 - val_loss: 54.9665 - 61ms/epoch - 12ms/step\n",
      "Epoch 9/250\n",
      "5/5 - 0s - loss: 53.5061 - val_loss: 42.8836 - 59ms/epoch - 12ms/step\n",
      "Epoch 10/250\n",
      "5/5 - 0s - loss: 39.8431 - val_loss: 31.1576 - 56ms/epoch - 11ms/step\n",
      "Epoch 11/250\n",
      "5/5 - 0s - loss: 26.8895 - val_loss: 20.7614 - 72ms/epoch - 14ms/step\n",
      "Epoch 12/250\n",
      "5/5 - 0s - loss: 16.2436 - val_loss: 12.7636 - 89ms/epoch - 18ms/step\n",
      "Epoch 13/250\n",
      "5/5 - 0s - loss: 8.8635 - val_loss: 8.0101 - 59ms/epoch - 12ms/step\n",
      "Epoch 14/250\n",
      "5/5 - 0s - loss: 5.1959 - val_loss: 6.0461 - 57ms/epoch - 11ms/step\n",
      "Epoch 15/250\n",
      "5/5 - 0s - loss: 4.2747 - val_loss: 5.7027 - 58ms/epoch - 12ms/step\n",
      "Epoch 16/250\n",
      "5/5 - 0s - loss: 4.5834 - val_loss: 5.8583 - 54ms/epoch - 11ms/step\n",
      "Epoch 17/250\n",
      "5/5 - 0s - loss: 4.8142 - val_loss: 5.7845 - 63ms/epoch - 13ms/step\n",
      "Epoch 18/250\n",
      "5/5 - 0s - loss: 4.5189 - val_loss: 5.5660 - 54ms/epoch - 11ms/step\n",
      "Epoch 19/250\n",
      "5/5 - 0s - loss: 4.0431 - val_loss: 5.4357 - 65ms/epoch - 13ms/step\n",
      "Epoch 20/250\n",
      "5/5 - 0s - loss: 3.7404 - val_loss: 5.4253 - 84ms/epoch - 17ms/step\n",
      "Epoch 21/250\n",
      "5/5 - 0s - loss: 3.6303 - val_loss: 5.4461 - 76ms/epoch - 15ms/step\n",
      "Epoch 22/250\n",
      "5/5 - 0s - loss: 3.4953 - val_loss: 5.3771 - 82ms/epoch - 16ms/step\n",
      "Epoch 23/250\n",
      "5/5 - 0s - loss: 3.4030 - val_loss: 5.2987 - 94ms/epoch - 19ms/step\n",
      "Epoch 24/250\n",
      "5/5 - 0s - loss: 3.3083 - val_loss: 5.2660 - 83ms/epoch - 17ms/step\n",
      "Epoch 25/250\n",
      "5/5 - 0s - loss: 3.2320 - val_loss: 5.2187 - 84ms/epoch - 17ms/step\n",
      "Epoch 26/250\n",
      "5/5 - 0s - loss: 3.0988 - val_loss: 5.1035 - 75ms/epoch - 15ms/step\n",
      "Epoch 27/250\n",
      "5/5 - 0s - loss: 3.0147 - val_loss: 5.0292 - 70ms/epoch - 14ms/step\n",
      "Epoch 28/250\n",
      "5/5 - 0s - loss: 2.9278 - val_loss: 4.9718 - 68ms/epoch - 14ms/step\n",
      "Epoch 29/250\n",
      "5/5 - 0s - loss: 2.8286 - val_loss: 4.9390 - 56ms/epoch - 11ms/step\n",
      "Epoch 30/250\n",
      "5/5 - 0s - loss: 2.7643 - val_loss: 4.8930 - 57ms/epoch - 11ms/step\n",
      "Epoch 31/250\n",
      "5/5 - 0s - loss: 2.7015 - val_loss: 4.8459 - 70ms/epoch - 14ms/step\n",
      "Epoch 32/250\n",
      "5/5 - 0s - loss: 2.6370 - val_loss: 4.8108 - 85ms/epoch - 17ms/step\n",
      "Epoch 33/250\n",
      "5/5 - 0s - loss: 2.6074 - val_loss: 4.7795 - 84ms/epoch - 17ms/step\n",
      "Epoch 34/250\n",
      "5/5 - 0s - loss: 2.5479 - val_loss: 4.7491 - 132ms/epoch - 26ms/step\n",
      "Epoch 35/250\n",
      "5/5 - 0s - loss: 2.4713 - val_loss: 4.7139 - 79ms/epoch - 16ms/step\n",
      "Epoch 36/250\n",
      "5/5 - 0s - loss: 2.4150 - val_loss: 4.6679 - 56ms/epoch - 11ms/step\n",
      "Epoch 37/250\n",
      "5/5 - 0s - loss: 2.4346 - val_loss: 4.6376 - 64ms/epoch - 13ms/step\n",
      "Epoch 38/250\n",
      "5/5 - 0s - loss: 2.3091 - val_loss: 4.6016 - 71ms/epoch - 14ms/step\n",
      "Epoch 39/250\n",
      "5/5 - 0s - loss: 2.2410 - val_loss: 4.5878 - 70ms/epoch - 14ms/step\n",
      "Epoch 40/250\n",
      "5/5 - 0s - loss: 2.1879 - val_loss: 4.5779 - 65ms/epoch - 13ms/step\n",
      "Epoch 41/250\n",
      "5/5 - 0s - loss: 2.1436 - val_loss: 4.5611 - 83ms/epoch - 17ms/step\n",
      "Epoch 42/250\n",
      "5/5 - 0s - loss: 2.0561 - val_loss: 4.5476 - 81ms/epoch - 16ms/step\n",
      "Epoch 43/250\n",
      "5/5 - 0s - loss: 2.0097 - val_loss: 4.5450 - 75ms/epoch - 15ms/step\n",
      "Epoch 44/250\n",
      "5/5 - 0s - loss: 1.9566 - val_loss: 4.5404 - 82ms/epoch - 16ms/step\n",
      "Epoch 45/250\n",
      "5/5 - 0s - loss: 1.9243 - val_loss: 4.5116 - 84ms/epoch - 17ms/step\n",
      "Epoch 46/250\n",
      "5/5 - 0s - loss: 1.8858 - val_loss: 4.4608 - 75ms/epoch - 15ms/step\n",
      "Epoch 47/250\n",
      "5/5 - 0s - loss: 1.8187 - val_loss: 4.3824 - 79ms/epoch - 16ms/step\n",
      "Epoch 48/250\n",
      "5/5 - 0s - loss: 1.7895 - val_loss: 4.3613 - 64ms/epoch - 13ms/step\n",
      "Epoch 49/250\n",
      "5/5 - 0s - loss: 1.7774 - val_loss: 4.3352 - 60ms/epoch - 12ms/step\n",
      "Epoch 50/250\n",
      "5/5 - 0s - loss: 1.7579 - val_loss: 4.3297 - 55ms/epoch - 11ms/step\n",
      "Epoch 51/250\n",
      "5/5 - 0s - loss: 1.7324 - val_loss: 4.3511 - 63ms/epoch - 13ms/step\n",
      "Epoch 52/250\n",
      "5/5 - 0s - loss: 1.6922 - val_loss: 4.3056 - 66ms/epoch - 13ms/step\n",
      "Epoch 53/250\n",
      "5/5 - 0s - loss: 1.5855 - val_loss: 4.2748 - 67ms/epoch - 13ms/step\n",
      "Epoch 54/250\n",
      "5/5 - 0s - loss: 1.5986 - val_loss: 4.2630 - 84ms/epoch - 17ms/step\n",
      "Epoch 55/250\n",
      "5/5 - 0s - loss: 1.5816 - val_loss: 4.2312 - 71ms/epoch - 14ms/step\n",
      "Epoch 56/250\n",
      "5/5 - 0s - loss: 1.5346 - val_loss: 4.1917 - 56ms/epoch - 11ms/step\n",
      "Epoch 57/250\n",
      "5/5 - 0s - loss: 1.5077 - val_loss: 4.1902 - 54ms/epoch - 11ms/step\n",
      "Epoch 58/250\n",
      "5/5 - 0s - loss: 1.5186 - val_loss: 4.1844 - 55ms/epoch - 11ms/step\n",
      "Epoch 59/250\n",
      "5/5 - 0s - loss: 1.4626 - val_loss: 4.1451 - 53ms/epoch - 11ms/step\n",
      "Epoch 60/250\n",
      "5/5 - 0s - loss: 1.4381 - val_loss: 4.1428 - 53ms/epoch - 11ms/step\n",
      "Epoch 61/250\n",
      "5/5 - 0s - loss: 1.4199 - val_loss: 4.1405 - 64ms/epoch - 13ms/step\n",
      "Epoch 62/250\n",
      "5/5 - 0s - loss: 1.4419 - val_loss: 4.1326 - 76ms/epoch - 15ms/step\n",
      "Epoch 63/250\n",
      "5/5 - 0s - loss: 1.4236 - val_loss: 4.1036 - 67ms/epoch - 13ms/step\n",
      "Epoch 64/250\n",
      "5/5 - 0s - loss: 1.3974 - val_loss: 4.0873 - 90ms/epoch - 18ms/step\n",
      "Epoch 65/250\n",
      "5/5 - 0s - loss: 1.3952 - val_loss: 4.0712 - 107ms/epoch - 21ms/step\n",
      "Epoch 66/250\n",
      "5/5 - 0s - loss: 1.3548 - val_loss: 4.0321 - 79ms/epoch - 16ms/step\n",
      "Epoch 67/250\n",
      "5/5 - 0s - loss: 1.3420 - val_loss: 4.0345 - 68ms/epoch - 14ms/step\n",
      "Epoch 68/250\n",
      "5/5 - 0s - loss: 1.2781 - val_loss: 4.0510 - 70ms/epoch - 14ms/step\n",
      "Epoch 69/250\n",
      "5/5 - 0s - loss: 1.2839 - val_loss: 4.0589 - 66ms/epoch - 13ms/step\n",
      "Epoch 70/250\n",
      "5/5 - 0s - loss: 1.3168 - val_loss: 4.0886 - 67ms/epoch - 13ms/step\n",
      "Epoch 71/250\n",
      "5/5 - 0s - loss: 1.3271 - val_loss: 4.0948 - 61ms/epoch - 12ms/step\n",
      "Epoch 72/250\n",
      "5/5 - 0s - loss: 1.2767 - val_loss: 4.0102 - 51ms/epoch - 10ms/step\n",
      "Epoch 73/250\n",
      "5/5 - 0s - loss: 1.1940 - val_loss: 3.9751 - 56ms/epoch - 11ms/step\n",
      "Epoch 74/250\n",
      "5/5 - 0s - loss: 1.1432 - val_loss: 3.9654 - 57ms/epoch - 11ms/step\n",
      "Epoch 75/250\n",
      "5/5 - 0s - loss: 1.1440 - val_loss: 3.9971 - 57ms/epoch - 11ms/step\n",
      "Epoch 76/250\n",
      "5/5 - 0s - loss: 1.1821 - val_loss: 3.9624 - 57ms/epoch - 11ms/step\n",
      "Epoch 77/250\n",
      "5/5 - 0s - loss: 1.1468 - val_loss: 3.9008 - 61ms/epoch - 12ms/step\n",
      "Epoch 78/250\n",
      "5/5 - 0s - loss: 1.0976 - val_loss: 3.8526 - 62ms/epoch - 12ms/step\n",
      "Epoch 79/250\n",
      "5/5 - 0s - loss: 1.0640 - val_loss: 3.8419 - 64ms/epoch - 13ms/step\n",
      "Epoch 80/250\n",
      "5/5 - 0s - loss: 1.0990 - val_loss: 3.8355 - 56ms/epoch - 11ms/step\n",
      "Epoch 81/250\n",
      "5/5 - 0s - loss: 1.0553 - val_loss: 3.7693 - 60ms/epoch - 12ms/step\n",
      "Epoch 82/250\n",
      "5/5 - 0s - loss: 1.0172 - val_loss: 3.7525 - 64ms/epoch - 13ms/step\n",
      "Epoch 83/250\n",
      "5/5 - 0s - loss: 1.0347 - val_loss: 3.7523 - 70ms/epoch - 14ms/step\n",
      "Epoch 84/250\n",
      "5/5 - 0s - loss: 1.0350 - val_loss: 3.7279 - 64ms/epoch - 13ms/step\n",
      "Epoch 85/250\n",
      "5/5 - 0s - loss: 1.0171 - val_loss: 3.7015 - 93ms/epoch - 19ms/step\n",
      "Epoch 86/250\n",
      "5/5 - 0s - loss: 0.9814 - val_loss: 3.6984 - 83ms/epoch - 17ms/step\n",
      "Epoch 87/250\n",
      "5/5 - 0s - loss: 1.0055 - val_loss: 3.7393 - 62ms/epoch - 12ms/step\n",
      "Epoch 88/250\n",
      "5/5 - 0s - loss: 0.9487 - val_loss: 3.7199 - 57ms/epoch - 11ms/step\n",
      "Epoch 89/250\n",
      "5/5 - 0s - loss: 0.9460 - val_loss: 3.7679 - 52ms/epoch - 10ms/step\n",
      "Epoch 90/250\n",
      "5/5 - 0s - loss: 0.9696 - val_loss: 3.7510 - 54ms/epoch - 11ms/step\n",
      "Epoch 91/250\n",
      "5/5 - 0s - loss: 0.9370 - val_loss: 3.7135 - 74ms/epoch - 15ms/step\n",
      "Epoch 92/250\n",
      "5/5 - 0s - loss: 0.8968 - val_loss: 3.6972 - 82ms/epoch - 16ms/step\n",
      "Epoch 93/250\n",
      "5/5 - 0s - loss: 0.9042 - val_loss: 3.6944 - 75ms/epoch - 15ms/step\n",
      "Epoch 94/250\n",
      "5/5 - 0s - loss: 0.9070 - val_loss: 3.6630 - 88ms/epoch - 18ms/step\n",
      "Epoch 95/250\n",
      "5/5 - 0s - loss: 0.8540 - val_loss: 3.6420 - 115ms/epoch - 23ms/step\n",
      "Epoch 96/250\n",
      "5/5 - 0s - loss: 0.8519 - val_loss: 3.6688 - 103ms/epoch - 21ms/step\n",
      "Epoch 97/250\n",
      "5/5 - 0s - loss: 0.8706 - val_loss: 3.6942 - 103ms/epoch - 21ms/step\n",
      "Epoch 98/250\n",
      "5/5 - 0s - loss: 0.8775 - val_loss: 3.6600 - 111ms/epoch - 22ms/step\n",
      "Epoch 99/250\n",
      "5/5 - 0s - loss: 0.8213 - val_loss: 3.6087 - 91ms/epoch - 18ms/step\n",
      "Epoch 100/250\n",
      "5/5 - 0s - loss: 0.7869 - val_loss: 3.5991 - 56ms/epoch - 11ms/step\n",
      "Epoch 101/250\n",
      "5/5 - 0s - loss: 0.7949 - val_loss: 3.5703 - 54ms/epoch - 11ms/step\n",
      "Epoch 102/250\n",
      "5/5 - 0s - loss: 0.7816 - val_loss: 3.5166 - 56ms/epoch - 11ms/step\n",
      "Epoch 103/250\n",
      "5/5 - 0s - loss: 0.7456 - val_loss: 3.4852 - 67ms/epoch - 13ms/step\n",
      "Epoch 104/250\n",
      "5/5 - 0s - loss: 0.7219 - val_loss: 3.4806 - 103ms/epoch - 21ms/step\n",
      "Epoch 105/250\n",
      "5/5 - 0s - loss: 0.7288 - val_loss: 3.4751 - 103ms/epoch - 21ms/step\n",
      "Epoch 106/250\n",
      "5/5 - 0s - loss: 0.7343 - val_loss: 3.4780 - 98ms/epoch - 20ms/step\n",
      "Epoch 107/250\n",
      "5/5 - 0s - loss: 0.7567 - val_loss: 3.4806 - 111ms/epoch - 22ms/step\n",
      "Epoch 108/250\n",
      "5/5 - 0s - loss: 0.7243 - val_loss: 3.4504 - 71ms/epoch - 14ms/step\n",
      "Epoch 109/250\n",
      "5/5 - 0s - loss: 0.6771 - val_loss: 3.4502 - 65ms/epoch - 13ms/step\n",
      "Epoch 110/250\n",
      "5/5 - 0s - loss: 0.6695 - val_loss: 3.4350 - 98ms/epoch - 20ms/step\n",
      "Epoch 111/250\n",
      "5/5 - 0s - loss: 0.6623 - val_loss: 3.3989 - 63ms/epoch - 13ms/step\n",
      "Epoch 112/250\n",
      "5/5 - 0s - loss: 0.6526 - val_loss: 3.3798 - 87ms/epoch - 17ms/step\n",
      "Epoch 113/250\n",
      "5/5 - 0s - loss: 0.6463 - val_loss: 3.3692 - 75ms/epoch - 15ms/step\n",
      "Epoch 114/250\n",
      "5/5 - 0s - loss: 0.6288 - val_loss: 3.3687 - 84ms/epoch - 17ms/step\n",
      "Epoch 115/250\n",
      "5/5 - 0s - loss: 0.6151 - val_loss: 3.3838 - 93ms/epoch - 19ms/step\n",
      "Epoch 116/250\n",
      "5/5 - 0s - loss: 0.6118 - val_loss: 3.3981 - 107ms/epoch - 21ms/step\n",
      "Epoch 117/250\n",
      "5/5 - 0s - loss: 0.6023 - val_loss: 3.4006 - 98ms/epoch - 20ms/step\n",
      "Epoch 118/250\n",
      "5/5 - 0s - loss: 0.5867 - val_loss: 3.4021 - 104ms/epoch - 21ms/step\n",
      "Epoch 119/250\n",
      "5/5 - 0s - loss: 0.5774 - val_loss: 3.3938 - 84ms/epoch - 17ms/step\n",
      "Epoch 120/250\n",
      "5/5 - 0s - loss: 0.5883 - val_loss: 3.3806 - 61ms/epoch - 12ms/step\n",
      "Epoch 121/250\n",
      "5/5 - 0s - loss: 0.5777 - val_loss: 3.3684 - 59ms/epoch - 12ms/step\n",
      "Epoch 122/250\n",
      "5/5 - 0s - loss: 0.5471 - val_loss: 3.3550 - 58ms/epoch - 12ms/step\n",
      "Epoch 123/250\n",
      "5/5 - 0s - loss: 0.5383 - val_loss: 3.3385 - 54ms/epoch - 11ms/step\n",
      "Epoch 124/250\n",
      "5/5 - 0s - loss: 0.5291 - val_loss: 3.3219 - 68ms/epoch - 14ms/step\n",
      "Epoch 125/250\n",
      "5/5 - 0s - loss: 0.5226 - val_loss: 3.2998 - 65ms/epoch - 13ms/step\n",
      "Epoch 126/250\n",
      "5/5 - 0s - loss: 0.5403 - val_loss: 3.3129 - 96ms/epoch - 19ms/step\n",
      "Epoch 127/250\n",
      "5/5 - 0s - loss: 0.5476 - val_loss: 3.2845 - 72ms/epoch - 14ms/step\n",
      "Epoch 128/250\n",
      "5/5 - 0s - loss: 0.5181 - val_loss: 3.2680 - 85ms/epoch - 17ms/step\n",
      "Epoch 129/250\n",
      "5/5 - 0s - loss: 0.5049 - val_loss: 3.2982 - 87ms/epoch - 17ms/step\n",
      "Epoch 130/250\n",
      "5/5 - 0s - loss: 0.5077 - val_loss: 3.3070 - 81ms/epoch - 16ms/step\n",
      "Epoch 131/250\n",
      "5/5 - 0s - loss: 0.5216 - val_loss: 3.3319 - 64ms/epoch - 13ms/step\n",
      "Epoch 132/250\n",
      "5/5 - 0s - loss: 0.5073 - val_loss: 3.2737 - 66ms/epoch - 13ms/step\n",
      "Epoch 133/250\n",
      "5/5 - 0s - loss: 0.4568 - val_loss: 3.2708 - 77ms/epoch - 15ms/step\n",
      "Epoch 134/250\n",
      "5/5 - 0s - loss: 0.4448 - val_loss: 3.2732 - 113ms/epoch - 23ms/step\n",
      "Epoch 135/250\n",
      "5/5 - 0s - loss: 0.4470 - val_loss: 3.2633 - 122ms/epoch - 24ms/step\n",
      "Epoch 136/250\n",
      "5/5 - 0s - loss: 0.4278 - val_loss: 3.2635 - 86ms/epoch - 17ms/step\n",
      "Epoch 137/250\n",
      "5/5 - 0s - loss: 0.4590 - val_loss: 3.3126 - 90ms/epoch - 18ms/step\n",
      "Epoch 138/250\n",
      "5/5 - 0s - loss: 0.4728 - val_loss: 3.2405 - 123ms/epoch - 25ms/step\n",
      "Epoch 139/250\n",
      "5/5 - 0s - loss: 0.4095 - val_loss: 3.1819 - 114ms/epoch - 23ms/step\n",
      "Epoch 140/250\n",
      "5/5 - 0s - loss: 0.4086 - val_loss: 3.1674 - 147ms/epoch - 29ms/step\n",
      "Epoch 141/250\n",
      "5/5 - 0s - loss: 0.4061 - val_loss: 3.1481 - 151ms/epoch - 30ms/step\n",
      "Epoch 142/250\n",
      "5/5 - 0s - loss: 0.3860 - val_loss: 3.1308 - 112ms/epoch - 22ms/step\n",
      "Epoch 143/250\n",
      "5/5 - 0s - loss: 0.3763 - val_loss: 3.1328 - 90ms/epoch - 18ms/step\n",
      "Epoch 144/250\n",
      "5/5 - 0s - loss: 0.3683 - val_loss: 3.1021 - 99ms/epoch - 20ms/step\n",
      "Epoch 145/250\n",
      "5/5 - 0s - loss: 0.3506 - val_loss: 3.1004 - 104ms/epoch - 21ms/step\n",
      "Epoch 146/250\n",
      "5/5 - 0s - loss: 0.4053 - val_loss: 3.1049 - 107ms/epoch - 21ms/step\n",
      "Epoch 147/250\n",
      "5/5 - 0s - loss: 0.4085 - val_loss: 3.0668 - 120ms/epoch - 24ms/step\n",
      "Epoch 148/250\n",
      "5/5 - 0s - loss: 0.3612 - val_loss: 3.0535 - 108ms/epoch - 22ms/step\n",
      "Epoch 149/250\n",
      "5/5 - 0s - loss: 0.3445 - val_loss: 3.0451 - 95ms/epoch - 19ms/step\n",
      "Epoch 150/250\n",
      "5/5 - 0s - loss: 0.3425 - val_loss: 3.0385 - 89ms/epoch - 18ms/step\n",
      "Epoch 151/250\n",
      "5/5 - 0s - loss: 0.3370 - val_loss: 3.0293 - 81ms/epoch - 16ms/step\n",
      "Epoch 152/250\n",
      "5/5 - 0s - loss: 0.3241 - val_loss: 3.0166 - 96ms/epoch - 19ms/step\n",
      "Epoch 153/250\n",
      "5/5 - 0s - loss: 0.3193 - val_loss: 3.0314 - 113ms/epoch - 23ms/step\n",
      "Epoch 154/250\n",
      "5/5 - 0s - loss: 0.3140 - val_loss: 3.0306 - 129ms/epoch - 26ms/step\n",
      "Epoch 155/250\n",
      "5/5 - 0s - loss: 0.3093 - val_loss: 3.0263 - 162ms/epoch - 32ms/step\n",
      "Epoch 156/250\n",
      "5/5 - 0s - loss: 0.2999 - val_loss: 3.0263 - 166ms/epoch - 33ms/step\n",
      "Epoch 157/250\n",
      "5/5 - 0s - loss: 0.3127 - val_loss: 2.9819 - 174ms/epoch - 35ms/step\n",
      "Epoch 158/250\n",
      "5/5 - 0s - loss: 0.3057 - val_loss: 2.9699 - 138ms/epoch - 28ms/step\n",
      "Epoch 159/250\n",
      "5/5 - 0s - loss: 0.2966 - val_loss: 2.9623 - 154ms/epoch - 31ms/step\n",
      "Epoch 160/250\n",
      "5/5 - 0s - loss: 0.2864 - val_loss: 2.9528 - 134ms/epoch - 27ms/step\n",
      "Epoch 161/250\n",
      "5/5 - 0s - loss: 0.2787 - val_loss: 2.9475 - 144ms/epoch - 29ms/step\n",
      "Epoch 162/250\n",
      "5/5 - 0s - loss: 0.2865 - val_loss: 2.9385 - 256ms/epoch - 51ms/step\n",
      "Epoch 163/250\n",
      "5/5 - 0s - loss: 0.2725 - val_loss: 2.9044 - 156ms/epoch - 31ms/step\n",
      "Epoch 164/250\n",
      "5/5 - 0s - loss: 0.2772 - val_loss: 2.8999 - 111ms/epoch - 22ms/step\n",
      "Epoch 165/250\n",
      "5/5 - 0s - loss: 0.2783 - val_loss: 2.8977 - 126ms/epoch - 25ms/step\n",
      "Epoch 166/250\n",
      "5/5 - 0s - loss: 0.2665 - val_loss: 2.8987 - 92ms/epoch - 18ms/step\n",
      "Epoch 167/250\n",
      "5/5 - 0s - loss: 0.2558 - val_loss: 2.9102 - 107ms/epoch - 21ms/step\n",
      "Epoch 168/250\n",
      "5/5 - 0s - loss: 0.2538 - val_loss: 2.9017 - 116ms/epoch - 23ms/step\n",
      "Epoch 169/250\n",
      "5/5 - 0s - loss: 0.2620 - val_loss: 2.8942 - 106ms/epoch - 21ms/step\n",
      "Epoch 170/250\n",
      "5/5 - 0s - loss: 0.2931 - val_loss: 2.8866 - 98ms/epoch - 20ms/step\n",
      "Epoch 171/250\n",
      "5/5 - 0s - loss: 0.2641 - val_loss: 2.8681 - 89ms/epoch - 18ms/step\n",
      "Epoch 172/250\n",
      "5/5 - 0s - loss: 0.2544 - val_loss: 2.9231 - 95ms/epoch - 19ms/step\n",
      "Epoch 173/250\n",
      "5/5 - 0s - loss: 0.2611 - val_loss: 2.9050 - 120ms/epoch - 24ms/step\n",
      "Epoch 174/250\n",
      "5/5 - 0s - loss: 0.2300 - val_loss: 2.8854 - 179ms/epoch - 36ms/step\n",
      "Epoch 175/250\n",
      "5/5 - 0s - loss: 0.2418 - val_loss: 2.8832 - 127ms/epoch - 25ms/step\n",
      "Epoch 176/250\n",
      "5/5 - 0s - loss: 0.2387 - val_loss: 2.8823 - 127ms/epoch - 25ms/step\n",
      "Epoch 177/250\n",
      "5/5 - 0s - loss: 0.2248 - val_loss: 2.8681 - 118ms/epoch - 24ms/step\n",
      "Epoch 178/250\n",
      "5/5 - 0s - loss: 0.2240 - val_loss: 2.8654 - 96ms/epoch - 19ms/step\n",
      "Epoch 179/250\n",
      "5/5 - 0s - loss: 0.2143 - val_loss: 2.8605 - 92ms/epoch - 18ms/step\n",
      "Epoch 180/250\n",
      "5/5 - 0s - loss: 0.2155 - val_loss: 2.8517 - 163ms/epoch - 33ms/step\n",
      "Epoch 181/250\n",
      "5/5 - 0s - loss: 0.2122 - val_loss: 2.8686 - 149ms/epoch - 30ms/step\n",
      "Epoch 182/250\n",
      "5/5 - 0s - loss: 0.2096 - val_loss: 2.8780 - 133ms/epoch - 27ms/step\n",
      "Epoch 183/250\n",
      "5/5 - 0s - loss: 0.2024 - val_loss: 2.8706 - 157ms/epoch - 31ms/step\n",
      "Epoch 184/250\n",
      "5/5 - 0s - loss: 0.2009 - val_loss: 2.8528 - 109ms/epoch - 22ms/step\n",
      "Epoch 185/250\n",
      "5/5 - 0s - loss: 0.1984 - val_loss: 2.8454 - 105ms/epoch - 21ms/step\n",
      "Epoch 186/250\n",
      "5/5 - 0s - loss: 0.2009 - val_loss: 2.8417 - 98ms/epoch - 20ms/step\n",
      "Epoch 187/250\n",
      "5/5 - 0s - loss: 0.1972 - val_loss: 2.8497 - 80ms/epoch - 16ms/step\n",
      "Epoch 188/250\n",
      "5/5 - 0s - loss: 0.1932 - val_loss: 2.8395 - 72ms/epoch - 14ms/step\n",
      "Epoch 189/250\n",
      "5/5 - 0s - loss: 0.2123 - val_loss: 2.8362 - 90ms/epoch - 18ms/step\n",
      "Epoch 190/250\n",
      "5/5 - 0s - loss: 0.2152 - val_loss: 2.8281 - 98ms/epoch - 20ms/step\n",
      "Epoch 191/250\n",
      "5/5 - 0s - loss: 0.1856 - val_loss: 2.8424 - 70ms/epoch - 14ms/step\n",
      "Epoch 192/250\n",
      "5/5 - 0s - loss: 0.2009 - val_loss: 2.8583 - 98ms/epoch - 20ms/step\n",
      "Epoch 193/250\n",
      "5/5 - 0s - loss: 0.1985 - val_loss: 2.8064 - 115ms/epoch - 23ms/step\n",
      "Epoch 194/250\n",
      "5/5 - 0s - loss: 0.1839 - val_loss: 2.7967 - 84ms/epoch - 17ms/step\n",
      "Epoch 195/250\n",
      "5/5 - 0s - loss: 0.2215 - val_loss: 2.7972 - 81ms/epoch - 16ms/step\n",
      "Epoch 196/250\n",
      "5/5 - 0s - loss: 0.1905 - val_loss: 2.8079 - 92ms/epoch - 18ms/step\n",
      "Epoch 197/250\n",
      "5/5 - 0s - loss: 0.1821 - val_loss: 2.8326 - 84ms/epoch - 17ms/step\n",
      "Epoch 198/250\n",
      "5/5 - 0s - loss: 0.1812 - val_loss: 2.8039 - 78ms/epoch - 16ms/step\n",
      "Epoch 199/250\n",
      "5/5 - 0s - loss: 0.1741 - val_loss: 2.7787 - 78ms/epoch - 16ms/step\n",
      "Epoch 200/250\n",
      "5/5 - 0s - loss: 0.1708 - val_loss: 2.7715 - 100ms/epoch - 20ms/step\n",
      "Epoch 201/250\n",
      "5/5 - 0s - loss: 0.1689 - val_loss: 2.7706 - 87ms/epoch - 17ms/step\n",
      "Epoch 202/250\n",
      "5/5 - 0s - loss: 0.1638 - val_loss: 2.7697 - 97ms/epoch - 19ms/step\n",
      "Epoch 203/250\n",
      "5/5 - 0s - loss: 0.1637 - val_loss: 2.7706 - 84ms/epoch - 17ms/step\n",
      "Epoch 204/250\n",
      "5/5 - 0s - loss: 0.1609 - val_loss: 2.7658 - 77ms/epoch - 15ms/step\n",
      "Epoch 205/250\n",
      "5/5 - 0s - loss: 0.1630 - val_loss: 2.7700 - 73ms/epoch - 15ms/step\n",
      "Epoch 206/250\n",
      "5/5 - 0s - loss: 0.1737 - val_loss: 2.7731 - 77ms/epoch - 15ms/step\n",
      "Epoch 207/250\n",
      "5/5 - 0s - loss: 0.1626 - val_loss: 2.7833 - 85ms/epoch - 17ms/step\n",
      "Epoch 208/250\n",
      "5/5 - 0s - loss: 0.1584 - val_loss: 2.7768 - 68ms/epoch - 14ms/step\n",
      "Epoch 209/250\n",
      "5/5 - 0s - loss: 0.1594 - val_loss: 2.7666 - 60ms/epoch - 12ms/step\n",
      "Epoch 210/250\n",
      "5/5 - 0s - loss: 0.1550 - val_loss: 2.7696 - 63ms/epoch - 13ms/step\n",
      "Epoch 211/250\n",
      "5/5 - 0s - loss: 0.1529 - val_loss: 2.7815 - 65ms/epoch - 13ms/step\n",
      "Epoch 212/250\n",
      "5/5 - 0s - loss: 0.1504 - val_loss: 2.7710 - 69ms/epoch - 14ms/step\n",
      "Epoch 213/250\n",
      "5/5 - 0s - loss: 0.1473 - val_loss: 2.7669 - 59ms/epoch - 12ms/step\n",
      "Epoch 214/250\n",
      "5/5 - 0s - loss: 0.1471 - val_loss: 2.7687 - 60ms/epoch - 12ms/step\n",
      "Epoch 215/250\n",
      "5/5 - 0s - loss: 0.1522 - val_loss: 2.7766 - 66ms/epoch - 13ms/step\n",
      "Epoch 216/250\n",
      "5/5 - 0s - loss: 0.1556 - val_loss: 2.7854 - 66ms/epoch - 13ms/step\n",
      "Epoch 217/250\n",
      "5/5 - 0s - loss: 0.1484 - val_loss: 2.8019 - 62ms/epoch - 12ms/step\n",
      "Epoch 218/250\n",
      "5/5 - 0s - loss: 0.1463 - val_loss: 2.8001 - 66ms/epoch - 13ms/step\n",
      "Epoch 219/250\n",
      "5/5 - 0s - loss: 0.1438 - val_loss: 2.7906 - 205ms/epoch - 41ms/step\n",
      "Epoch 220/250\n",
      "5/5 - 0s - loss: 0.1410 - val_loss: 2.7831 - 106ms/epoch - 21ms/step\n",
      "Epoch 221/250\n",
      "5/5 - 0s - loss: 0.1424 - val_loss: 2.7898 - 76ms/epoch - 15ms/step\n",
      "Epoch 222/250\n",
      "5/5 - 0s - loss: 0.1343 - val_loss: 2.7768 - 96ms/epoch - 19ms/step\n",
      "Epoch 223/250\n",
      "5/5 - 0s - loss: 0.1360 - val_loss: 2.7678 - 93ms/epoch - 19ms/step\n",
      "Epoch 224/250\n",
      "5/5 - 0s - loss: 0.1346 - val_loss: 2.7632 - 124ms/epoch - 25ms/step\n",
      "Epoch 225/250\n",
      "5/5 - 0s - loss: 0.1334 - val_loss: 2.7591 - 130ms/epoch - 26ms/step\n",
      "Epoch 226/250\n",
      "5/5 - 0s - loss: 0.1340 - val_loss: 2.7584 - 110ms/epoch - 22ms/step\n",
      "Epoch 227/250\n",
      "5/5 - 0s - loss: 0.1299 - val_loss: 2.7557 - 102ms/epoch - 20ms/step\n",
      "Epoch 228/250\n",
      "5/5 - 0s - loss: 0.1296 - val_loss: 2.7657 - 87ms/epoch - 17ms/step\n",
      "Epoch 229/250\n",
      "5/5 - 0s - loss: 0.1313 - val_loss: 2.7701 - 87ms/epoch - 17ms/step\n",
      "Epoch 230/250\n",
      "5/5 - 0s - loss: 0.1330 - val_loss: 2.7647 - 73ms/epoch - 15ms/step\n",
      "Epoch 231/250\n",
      "5/5 - 0s - loss: 0.1253 - val_loss: 2.7496 - 81ms/epoch - 16ms/step\n",
      "Epoch 232/250\n",
      "5/5 - 0s - loss: 0.1290 - val_loss: 2.7461 - 69ms/epoch - 14ms/step\n",
      "Epoch 233/250\n",
      "5/5 - 0s - loss: 0.1257 - val_loss: 2.7515 - 73ms/epoch - 15ms/step\n",
      "Epoch 234/250\n",
      "5/5 - 0s - loss: 0.1236 - val_loss: 2.7666 - 109ms/epoch - 22ms/step\n",
      "Epoch 235/250\n",
      "5/5 - 0s - loss: 0.1249 - val_loss: 2.7707 - 95ms/epoch - 19ms/step\n",
      "Epoch 236/250\n",
      "5/5 - 0s - loss: 0.1291 - val_loss: 2.7749 - 87ms/epoch - 17ms/step\n",
      "Epoch 237/250\n",
      "5/5 - 0s - loss: 0.1280 - val_loss: 2.7791 - 139ms/epoch - 28ms/step\n",
      "Epoch 238/250\n",
      "5/5 - 0s - loss: 0.1240 - val_loss: 2.7847 - 85ms/epoch - 17ms/step\n",
      "Epoch 239/250\n",
      "5/5 - 0s - loss: 0.1268 - val_loss: 2.7978 - 71ms/epoch - 14ms/step\n",
      "Epoch 240/250\n",
      "5/5 - 0s - loss: 0.1258 - val_loss: 2.7790 - 79ms/epoch - 16ms/step\n",
      "Epoch 241/250\n",
      "5/5 - 0s - loss: 0.1177 - val_loss: 2.7608 - 78ms/epoch - 16ms/step\n",
      "Epoch 242/250\n",
      "5/5 - 0s - loss: 0.1191 - val_loss: 2.7569 - 71ms/epoch - 14ms/step\n",
      "Epoch 243/250\n",
      "5/5 - 0s - loss: 0.1159 - val_loss: 2.7721 - 73ms/epoch - 15ms/step\n",
      "Epoch 244/250\n",
      "5/5 - 0s - loss: 0.1169 - val_loss: 2.7817 - 64ms/epoch - 13ms/step\n",
      "Epoch 245/250\n",
      "5/5 - 0s - loss: 0.1232 - val_loss: 2.7826 - 63ms/epoch - 13ms/step\n",
      "Epoch 246/250\n",
      "5/5 - 0s - loss: 0.1282 - val_loss: 2.7283 - 69ms/epoch - 14ms/step\n",
      "Epoch 247/250\n",
      "5/5 - 0s - loss: 0.1204 - val_loss: 2.7045 - 77ms/epoch - 15ms/step\n",
      "Epoch 248/250\n",
      "5/5 - 0s - loss: 0.1268 - val_loss: 2.6979 - 102ms/epoch - 20ms/step\n",
      "Epoch 249/250\n",
      "5/5 - 0s - loss: 0.1154 - val_loss: 2.7234 - 142ms/epoch - 28ms/step\n",
      "Epoch 250/250\n",
      "5/5 - 0s - loss: 0.1270 - val_loss: 2.7767 - 153ms/epoch - 31ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x20ddad9f6a0>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=250, batch_size=10, validation_data=(X_test, y_test),verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (Neural Network): 2.7767341136932373\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "mse_nn = model.evaluate(X_test, y_test,verbose=0)\n",
    "print(f'Mean Squared Error (Neural Network): {mse_nn}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Thrinath Nelaturi\\anaconda3\\envs\\intro_python\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the model to a file\n",
    "model.save(\"stock_price_prediction_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferencing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import joblib\n",
    "# Load the saved model\n",
    "loaded_model = load_model(\"stock_price_prediction_model.h5\")\n",
    "\n",
    "# Load the saved scaler\n",
    "scaler_filename = \"scaler.joblib\"  # Adjust the filename as per your actual filename\n",
    "loaded_scaler = joblib.load(scaler_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have loaded the necessary libraries, loaded the model, and preprocessed the input data\n",
    "open_val = 12.3900003433227\n",
    "high_val = 12.5\n",
    "low_val = 12.16\n",
    "volume_val = 133775900\n",
    "close_val = 12.19\n",
    "\n",
    "positive_sentiment_val = 0.98\n",
    "negative_sentiment_val = 0.93\n",
    "neutral_sentiment_val = 0.95\n",
    "\n",
    "\n",
    "input = [open_val, high_val, low_val, volume_val, close_val, positive_sentiment_val, negative_sentiment_val, neutral_sentiment_val]+[0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 90ms/step\n",
      "Predicted Next_Week_Close: 5.061106\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sample input data (replace this with your actual input)\n",
    "single_input_data = np.array([input])\n",
    "# Normalize the new input data using the loaded scaler\n",
    "new_row_scaled = loaded_scaler.fit_transform(single_input_data)\n",
    "\n",
    "# Make predictions\n",
    "prediction = model.predict(new_row_scaled)\n",
    "\n",
    "# Print the predicted value\n",
    "print(\"Predicted Next_Week_Close:\", prediction.flatten()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intro_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
